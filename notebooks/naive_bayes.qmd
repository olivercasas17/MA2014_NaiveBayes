---
title: "naive_bayes"
format: html
editor: source
---
# Paquetes, lectura de datos y split
```{r}
library(e1071)
library(dplyr)
library(caret)
library(tidymodels)
library(naivebayes)
library(yardstick)
library(discrim)
```

```{r}
historias = readRDS("../data/sparse_matrix.rds")
```

Separar los datos en entrenamiento y prueba

```{r}
set.seed(1234)
historias_split = initial_split(historias, prop = 0.7)
```

```{r}
historias_train = training(historias_split)
historias_test = testing(historias_split)
```

# Clasificador con todas las categorias
## Usando la libreria e1071

```{r}
NB_cl = naiveBayes(categoria ~ ., data = historias_train)
```

```{r}
y_pred = predict(NB_cl, newdata = historias_test)
historias_test$categoria = factor(historias_test$categoria, levels = levels(y_pred))
```

```{r}
cm = table(historias_test$categoria, y_pred)
#cm
```

```{r}
results <- tibble(
  truth = historias_test$categoria,
  predicted = y_pred
)

accuracy = accuracy(results, truth, predicted,)$.estimate
precision = precision(results, truth, predicted, estimator = "macro")$.estimate
recall = recall(results, truth, predicted, estimator = "macro")$.estimate
f1_score = f_meas(results, truth, predicted, estimator = "macro")$.estimate

metrics <- tibble(
              accuracy,
              precision,
              recall,
              f1_score
)
metrics
```

## Usando la libreria naivebayes()
```{r}
NB_cl <- naive_bayes(categoria ~ ., data = historias_train)
```

```{r}
y_pred <- predict(NB_cl, newdata = historias_test)
```
```{r}
results <- tibble(
  truth = historias_test$categoria,
  predicted = y_pred
)

accuracy = accuracy(results, truth, predicted,)$.estimate
precision = precision(results, truth, predicted, estimator = "macro")$.estimate
recall = recall(results, truth, predicted, estimator = "macro")$.estimate
f1_score = f_meas(results, truth, predicted, estimator = "macro")$.estimate

metrics <- tibble(
              accuracy,
              precision,
              recall,
              f1_score
)
metrics
```

# Ahora con la dicotomizaci칩n

```{r}
historias_D <- readRDS("../data/sparse_matrix.rds")

historias_D <- historias_D |>
  mutate(categoria = if_else(categoria == "Apparitions / Voices / Touches", "Apparitions / Voices / Touches",
                             "otra"))

```

```{r}
set.seed(1234)
historiasD_split = initial_split(historias_D, prop = 0.7)
```

```{r}
historiasD_train = training(historiasD_split)
historiasD_test = testing(historiasD_split)
```

## Usando la libreria e1071
```{r}
NB_cl_D = naiveBayes(categoria ~ ., data = historiasD_train)
```

```{r}
y_pred_D = predict(NB_cl_D, newdata = historiasD_test)
historiasD_test$categoria = factor(historiasD_test$categoria, levels = levels(y_pred_D))
```

```{r}
cmD = table(historiasD_test$categoria, y_pred_D)
#cmD
```

Metricas
```{r}
results <- tibble(
  truth = historiasD_test$categoria,
  predicted = y_pred_D
)

accuracy = accuracy(results, truth, predicted,)$.estimate
precision = precision(results, truth, predicted, estimator = "macro")$.estimate
recall = recall(results, truth, predicted, estimator = "macro")$.estimate
f1_score = f_meas(results, truth, predicted, estimator = "macro")$.estimate

metrics <- tibble(
              accuracy,
              precision,
              recall,
              f1_score
)
metrics
```


## Ahora con la naivebayes()
```{r}
library(naivebayes)

NB_cl <- naive_bayes(categoria ~ ., data = historiasD_train, usepoisson = TRUE, laplace = 0)
```

```{r}
y_pred <- predict(NB_cl, newdata = historiasD_test)
historiasD_test$categoria = factor(historiasD_test$categoria, levels = levels(y_pred))
```

```{r}
results <- tibble(
  truth = historiasD_test$categoria,
  predicted = y_pred
)

accuracy = accuracy(results, truth, predicted,)$.estimate
precision = precision(results, truth, predicted, estimator = "macro")$.estimate
recall = recall(results, truth, predicted, estimator = "macro")$.estimate
f1_score = f_meas(results, truth, predicted, estimator = "macro")$.estimate

metrics <- tibble(
              accuracy,
              precision,
              recall,
              f1_score
)
metrics
```
##CrossValidation Laplace
```{r}
# Definir rango de valores para laplace y valores fijos para los otros par치metros
laplace_grid <- expand.grid(
  laplace = c(0, 0.5, 1, 2, 5),
  usekernel = FALSE,   # FALSE si quieres Naive Bayes "cl치sico"
  adjust = 1           # ajuste para kernel density (irrelevante si usekernel=FALSE)
)

# Control para cross-validation
train_control <- trainControl(method = "cv", number = 5) # 5-fold CV

# Ajustar el modelo usando caret para tunear laplace
set.seed(123)
NB_cv <- train(
  categoria ~ ., 
  data = historiasD_train,
  method = "naive_bayes",
  trControl = train_control,
  tuneGrid = laplace_grid
)

# Revisar el mejor par치metro
NB_cv$bestTune
```



